<!-- About Section -->
<section class="success" id="about">
  <div class="container text-center">
    <!-- Section Title -->
    <div class="row">
      <div class="col-lg-12 text-center">
        <h2>About EvalEval</h2>
        <hr>
      </div>
    </div>

    <!-- Intro Paragraphs -->
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1">
        <p><strong>We’re building a coalition on evaluating evaluations (Eval Eval)!</strong></p>
        <p>We are a researcher community developing scientifically grounded research outputs and robust deployment infrastructure for broader impact evaluations.</p>
        <p>Hosted by <strong>Hugging Face, University of Edinburgh, and EleutherAI</strong>, this cross‑sector and interdisciplinary coalition will operate across working groups:</p>
      </div>
    </div>

    <!-- Current Projects Columns (with spacing & adjusted font‐sizes) -->
    <div class="row text-center" style="padding: 40px 0;">
      <!-- Research Column -->
      <div class="col-md-4">
        <h4 style="font-size: 2em;">Research</h4>
        <ul class="list-unstyled" style="font-size: 20px;">
          <li>Evaluation Cards</li>
          <li>Benchmark Saturation</li>
          <li>Evaluation Science</li>
        </ul>
      </div>

      <!-- Infrastructure Column -->
      <div class="col-md-4">
        <h4 style="font-size: 2em;">Infrastructure</h4>
        <ul class="list-unstyled" style="font-size: 20px;">
          <li>Single Data Format and Caching Evals</li>
          <li>Evaluation Harness and Tutorials</li>
        </ul>
      </div>

      <!-- Organization Column -->
      <div class="col-md-4">
        <h4 style="font-size: 2em;">Organization</h4>
        <ul class="list-unstyled" style="font-size: 20px;">
          <li>Community Engagement</li>
          <li>Research Workshops</li>
        </ul>
      </div>
    </div>

    <!-- Remaining Narrative -->
    <div class="row">
      <div class="col-lg-10 col-lg-offset-1">
        <p>The flawed state of evaluations, lack of consensus for documenting evaluation applicability and utility, and disparate coverage of broader impact categories hinder adoption, scientific research, and policy analysis of generative AI systems. Coalition members are working collectively on improving the state of evaluations.</p>
        <p>In addition to working group outputs, positive effects can include influencing research papers’ Broader Impact sections, how evaluations are released, and overall public policy.</p>
        <p>Our <strong>NeurIPS 2024 “Evaluating Evaluations”</strong> kicked off the latest work streams, highlighting tiny paper submissions that provoked and advanced the state of evaluations. Our original framework for establishing categories of social impact is now published as a chapter in the <em>Oxford Handbook on Generative AI</em> and we hope will guide standards for Broader Impact analyses. We’ve previously hosted a series of workshops to hone the framework.</p>
        <p><strong>Interested in joining?</strong> <a href="https://docs.google.com/forms/d/e/1FAIpQLSe3Zks5jyCfmBYCyQl4lgLVXCAXfxxtXTPlCxJpIbhBnmptjg/viewform" target="_blank">Submit this form to join our Slack!</a></p>
      </div>
    </div>
  </div>
</section>
